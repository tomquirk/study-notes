## CNN
### Dropout
- fastai dropouts out twice in final layers by default

  - can turn it off by setting dropout to 0 and passsing empty list to fully connected layer param

- might need more dropout for larger architectures

- your only goal is to reduce validation loss; if that means overfitting a bit, so be it. You'll need to learn how much overfitting is okay for your problem

-can pass different dropout per layer

## Structured data
- some things, although continuous, may be better off as categorical (like day of week)
  - good rule of thumb: if floating point: continuous
  - consider binning
- fastai.proc_df
  - handles missing values
  - scales (neural nets like vals between 0-1)
- do lrfind

### embeddings
- a "distributed representation"
  - represent 1 category with multiple floats
- representing categorical vars in NN
- start out with integer between 0 and (max)
- when we create learner, we specify the embedding sizes for each cat_var
  - min(50, n+1//2)


## NLP (1:31:00)
- language modelling: model that can predict the next word of a given sentence